\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
% \usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage[hidelinks,colorlinks=true,linkcolor=blue,citecolor=blue]{hyperref}
\usepackage[backend=biber]{biblatex}
\addbibresource{cites.bib}

\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}
\title{Verifying Rust Standard Library }

\author{\IEEEauthorblockN{Kosumi Chan}
% \IEEEauthorblockA{\textit{dept. name of organization (of Aff.)} \\
\textit{The University of North Carolina at
Chapel Hill}\\
kosumi@cs.unc.edu
% City, Country \\
% }
\and
\IEEEauthorblockN{Hu Guo}
%\IEEEauthorblockA{\textit{dept. name of organization (of Aff.)} \\
\textit{The University of North Carolina at
Chapel Hill}\\
%City, Country \\
huhu8@cs.unc.edu}
\maketitle

\begin{abstract}
Rust's \texttt{std::collections} library provides a set of core data structures that are widely used in systems programming. Although Rust's ownership model helps prevent memory-safety errors, it does not alone guarantee full functional correctness or security against logical vulnerabilities. In this project, we propose using Verus, an SMT-based deductive verifier for Rust, to formally specify and verify key operations of \texttt{std::collections}, such as \texttt{Vec} and \texttt{HashMap}. We aim to prove that common operations preserve specified invariants, thus strengthening correctness and security guarantees for downstream Rust applications.
\end{abstract}

\begin{IEEEkeywords}
Verus, Rust, Verification 
\end{IEEEkeywords}

\section{Introduction}
Rust\cite{matsakis2014rust} is a modern programming language with an affine type system that checks memory safety at compile time. Its memory safety guarantees, fearless concurrency, and zero-cost abstractions are compelling for systems programming, where safety and performance are both critical. For code whose safety cannot be statically checked by the compiler, Rust provides the \texttt{unsafe} keyword to bypass checks. 


Some common idioms include:
\begin{enumerate}
    \item \textbf{Minimize and Isolate:} Keep \texttt{unsafe} blocks as small as possible and restricted to modules or functions that perform low-level operations. This limits the scope of potential errors and makes auditing easier.
    \item \textbf{Encapsulate Unsafe in Safe Abstractions:} Hide \texttt{ Unsafe} code behind a public, safe API. This ensures that the rest of the codebase remains in the safe Rust realm, relying on the well-documented interface provided by the unsafe implementation.
    \item \textbf{Document Invariants and Assumptions:} Clearly state the assumptions the \texttt{unsafe} code makes (such as pointer validity or aliasing rules). Documentation is critical for future maintenance and for reviewers to understand why the code is correct despite bypassing some of the Rust compile time checks.
\end{enumerate}


The Rust standard library(std) is a prime example of these idioms in action. Internally, it employs many unsafe operations not only for low-level control but also for performance. All public and private APIs of std are well documented. Usually a user only needs to interact with the safe API of std.  


Because std supports the entire Rust ecosystem, ensuring its safety and correctness is paramount. Manual auditing by library maintainers, dynamic testing and incomplete static analysis can reveal the existence of bugs, but are insufficient to prove correctness. However, deductive verification can prove that the implementation refines the specification.           


In the paper, we explore how deductive verification can formally prove the functional correctness of the implementation of the Rust standard library. We take a modular approach: write formal specifications for a module based on its informal documentation and supplement proofs to help the verifier prove the refinement theorem. Specifically, we use the state-of-the-art deductive program verification tool Verus\cite{verus}. 
        
\section{State of the Art for Verifying Rust Program}
Formal verification of Rust code is an active research area. However, most existing automated verifiers cannot reason about unsafe code. 

\textbf{Kani}\cite{kani} is a model checker for Rust code. Translates the Rust program into an intermediate representation for verification and then invokes CBMC (C bounded model checker)\cite{kroening2023cbmccboundedmodel}, which checks the IR for property violations by symbolic execution and SAT solving. Kani emphasizes soundness over completeness. It requires minimal user annotations and enables push-button verification of safety properties. However, it has limited specification expressiveness compared to deductive verification.   

\textbf{RefinedRust}\cite{RefinedRust} aims to produce foundational proofs of Rust code in the Coq proof assistant. It is a semi-automated deductive verifier that removes most of Rustc from the TCB(Trusted Computing Base). The verification of a simplified \texttt{Vec} implementation takes 22 minutes CPU on an Apple M1 Max processor due to the blow-up caused by the lowering from surface Rust to MIR by Rustc. Currently, it does not support concurrency.       


% VeriFast\cite{foroushaani2022modularformalverificationrust} extends a classic separation‑logic verifier to Rust, requiring detailed manual annotations for memory separation


\section{Background}

\subsection{Rust}
\subsubsection{Ownership policy}
Rust's ownership policy, enforced by its affine-type system, requires that a memory object must be exclusively owned by a variable at a time. A memory object can be borrowed temporarily as references from the owner. There can be at most one outstanding mutable reference or multiple immutable references at a time. When the ownership policy is respected, Rust ensures spatial and temporal memory safety. For operations that may break the ownership policy but cannot be checked by the compiler, the Rust compiler requires the programmer to use the \texttt{unsafe} keyword to mark such code block and it is the programmer's responsibility to ensure that unsafe code does not invalidate the ownership policy.      
\subsubsection{The Rust Standard Library}
The Rust Standard Library (\texttt{std}) provides essential building blocks for system programming, such as basic I/O, concurrency primitives, and fundamental data types. Within the standard library, the \texttt{std::collections} module offers a suite of commonly used data structures, including \texttt{Vec} (a dynamic array), \texttt{BTreeMap}, \texttt{HashMap}, \texttt{LinkedList}, and more. These collections are implemented with Rust’s ownership policy in mind, often using \texttt{ unsafe} internals to achieve performance while maintaining safe interfaces. The library also includes synchronization primitives such as \texttt{Mutex} and \texttt{RwLock} in \texttt{std::sync}, which, together with Rust's borrowing rules, enable higher-level concurrency patterns without exposing end-users to data races.  

Our work focuses on verifying subsets of \texttt{std::collections} (such as \texttt{BTreeMap} or \texttt{Vec}) using formal methods, thus providing stronger guarantees of safety and correctness than can be offered by Rust’s compiler checks alone.



\subsection{Verus and Rust’s Affine Type System}

Verus builds on Rust's affine (ownership-based) system to streamline the verification of functional correctness. In Rust, each piece of data has either a single mutable owner or multiple read-only owners at any point in time, preventing data races by design. Verus encodes these ownership guarantees into a framework \emph{permission-based reasoning}, where references carry logical 'tokens' that indicate whether they grant exclusive write access or shared read access. This approach allows Verus to rely on the checks of the Rust compiler for memory safety, so many low-level properties (for example, absence of data races, valid pointer usage) come 'free'. Consequently, users can focus on higher-level correctness, such as data structure invariants or algorithmic properties.

Beyond permission reasoning, Verus employs an \emph{efficient SMT encoding} that translates Rust code plus embedded specifications (ghost variables, loop invariants, etc.) into logical formulas for an SMT solver. Using the static guarantees of the Rust-type system, Verus can generate simpler verification conditions compared to languages with weaker memory models. This often results in faster solver times and less manual annotation overhead than fully general deductive verifiers would require.

Another key feature is \emph{linear ghost state}, which allows authors to write auxiliary 'ghost' code that does not compile to machine code but encodes ephemeral invariants or transformations. Unlike Rust's linear types, ghost variables cannot be duplicated or aliased in ways that violate logical constraints. This state can record information on the internal changes of a data structure over time, guiding the solver to prove that all required invariants hold after each operation. Because ghost code does not affect runtime behavior, developers are free to add detailed proof hints without performance penalties.

In general, by unifying the Rust ownership model with permission-based reasoning, efficient SMT encoding, and linear ghost state, Verus offers a relatively automatic path to verifying higher-level correctness properties of Rust programs while relying on the robust compiler foundation for memory safety.




\section{Threat Model}

We assume that an adversary could attempt to exploit logical flaws in \texttt{std::collections} if a data structure behaves inconsistently under concurrent usage or corner-case operations. Although Rust's borrow checker already prevents many common memory safety errors (such as data races and use-after-free), it does not guarantee functional correctness or invariants related to data structure behavior. Consequently, our verification targets a class of attacks in which incorrect library logic might be leveraged to corrupt data or cause unexpected behavior.

\begin{itemize}
\item \textbf{Data-Structure Invariant Violations:} An adversary may trigger key ordering violations or disrupt node relationships in a \texttt{BTreeMap} (e.g., by exploiting an unverified insertion routine that leads to a broken internal structure). If such structural invariants are not formally proven, an attacker could cause lookups or iterations to fail unexpectedly.
\item \textbf{Potential Concurrency Bugs:} If we pursue partial concurrency verification, adversaries might exploit incomplete synchronization mechanisms or overlooked atomic guarantees. Race conditions could violate internal invariants, allowing inconsistent reads or writes that undermine correctness or even create denial-of-service conditions.
\end{itemize}

We do not address hardware-level attacks, compiler bugs, or misuse of \texttt{unsafe} Rust blocks external to the data structures being verified. These lie outside our verification scope, as our project focuses on proving correctness within safe Rust and the formal methodology provided by Verus. However, ensuring strong functional invariants is an essential step in making Rust collection libraries more robust against adversarial misuse.

\section{Approach}

\subsection{Specification}
To verify \texttt{Vec} and \texttt{BTreeMap}, we will introduce a combination of preconditions, postconditions, loop invariants, and ghost variables directly into their Rust implementations. For example, \texttt{BTreeMap::insert (key, value)} must preserve order and maintain a valid tree structure to ensure correct searches and iterations. Meanwhile, rebalancing or node-splitting operations must uphold parent-child relationships so that the tree remains valid at every intermediate step. To capture invariants beyond the native checks of Rust, we rely on ghost variables and lemmas, which allow us to encode properties that do not exist at run-time but guide the verifier in proving functional correctness. In any concurrent scenarios, these same ghost annotations can help formalize atomic invariants or concurrency-related postconditions.

\subsection{Push-Button Verification}
We embed proof hints inline with Rust code, allowing Verus to translate both the implementation and our specifications into verification conditions for an SMT solver. Once the solver successfully fulfills these conditions, we gain confidence that the annotated invariants hold under all valid executions. The Rust ownership model further aids the verification process, as many low-level memory-safety properties are already enforced by the compiler, reducing the annotation overhead required to establish correctness.

\subsection{Potential Risks}
Although Rust’s affine type system provides a strong foundation for memory safety, specifying the logic of a B tree or other complex data structures can still be verbose. If we incorporate concurrency aspects, correctly articulating atomic invariants becomes even more challenging, especially since Verus’s concurrency features may not fully address advanced synchronization patterns. Moreover, large or nested operations (such as node splits in a B-tree) can lead to complex verification conditions that risk solver timeouts. Despite these potential hurdles, our aim is to systematically refine our annotations and approach to keep proof complexity manageable.

\section{Evaluation}
Our primary metrics for success include the thoroughness of verified invariants, the overall annotation effort, and the degree to which concurrency properties (if explored) can be guaranteed. For correctness coverage, we will focus on essential methods in \texttt{Vec} and \texttt{BTreeMap}—for example, \texttt{insert}, \texttt{remove}, and node-splitting operations. The notation effort will be gauged by measuring the ratio of proof-related lines to functional code. If we do explore concurrency proofs, we will track how well our specifications hold under concurrent usage and whether any simplified concurrency wrappers can demonstrate Verus’s capabilities.

\subsection{Mid-Point Evaluation}
By Week 11 of the 16-week semester, we intend to have at least the core operations of \texttt{Vec} or basic insertion in \texttt{BTreeMap} fully annotated and passing Verus checks, indicating that our approach is technically viable. This midpoint assessment will also help us identify any major solver performance bottlenecks and refine our specification strategies before tackling more sophisticated operations or concurrency.

\subsection{Final Evaluation}
For the final submission, we plan to present a set of verified operations in \texttt{BTreeMap}, along with any additional results for \texttt{Vec}, time permitting. We will document any attempts to model concurrency, discuss successes or obstacles, and provide a qualitative comparison to other formal verification efforts in Rust. We also intend to analyze whether the annotation overhead is reasonable given the complexity of the operations verified and to highlight any invariants or proof techniques that proved especially valuable for ensuring correctness.


\section{Plan of Work}
\noindent\textbf{Weeks 1--8 (Completed):}
\begin{itemize}
\item Verus was installed and tested with small Rust examples.
\item Explored the feasibility of verifying \texttt{HashMap} before pivoting to \texttt{BTreeMap}.
\item Drafted initial specs for \texttt{Vec} and simple B-tree structures.
\end{itemize}

\noindent\textbf{Week 9--10:}
\begin{itemize}
\item Expand annotations for core \texttt{BTreeMap} operations (insert/remove).
\item Resolve any immediate solver errors and refine the approach as needed.
\item Begin documentation for the final paper.
\end{itemize}

\noindent\textbf{Week 11--12:}
\begin{itemize}
\item Verify the verification of \texttt{insert}, \texttt{remove} and relevant invariants.
\item Investigate concurrency (if feasible); draft concurrency-related specifications.
\item Track proof overhead and solver performance.
\end{itemize}

\noindent\textbf{Week 13:}
\begin{itemize}
\item Evaluate proof coverage; identify gaps for the final push.
\item Draft of major sections of the final paper (methodology, results, limitations).
\end{itemize}

\noindent\textbf{Week 14--15:}
\begin{itemize}
\item Finalize verification of chosen operations and concurrency aspects (if any).
\item Integrate feedback from peers/instructor.
\item Complete and polish workshop-style paper.
\end{itemize}

\noindent\textbf{Week 16:}
\begin{itemize}
\item Finalize code artifacts.
\item Prepare and deliver a class presentation.
\end{itemize}

\subsection{Goals}
\noindent\textbf{Minimum Goal:} Prove core \texttt{Vec} operations (push/pop) for basic functional correctness under single-threaded usage.\\
\textbf{Expected Goal:} Verify a set of \texttt{BTreeMap} operations (insert/remove) with relevant invariants and partial concurrency checks if time allows.\\
\textbf{Reach Goal:} Thoroughly verify \texttt{BTreeMap} across a broader range of operations, including concurrency invariants.

\section{Who Did What}
\begin{itemize}
\item \textbf{Kosumi Chan:} Investigated the background on concurrent separation logic, refined approach for \texttt{BTreeMap} specifications, and authored the concurrency threat model.
\item \textbf{Hu Guo:} Explored Verus' use of Rust's affine-type system, implemented initial verification of \texttt{Vec} operations, and drafted a pivot strategy from \texttt{HashMap} to \texttt{BTreeMap}.
\end{itemize}



\end{document}
